{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === norvig's code\n",
    "# steal from it without shame\n",
    "\n",
    "# import re\n",
    "# from collections import Counter\n",
    "\n",
    "# def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "# def P(word, N=sum(WORDS.values())): \n",
    "#     \"Probability of `word`.\"\n",
    "#     return WORDS[word] / N\n",
    "\n",
    "# def correction(word): \n",
    "#     \"Most probable spelling correction for word.\"\n",
    "#     return max(candidates(word), key=P)\n",
    "\n",
    "# def candidates(word): \n",
    "#     \"Generate possible spelling corrections for word.\"\n",
    "#     return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "# def known(words): \n",
    "#     \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "#     return set(w for w in words if w in WORDS)\n",
    "\n",
    "# def edits1(word):\n",
    "#     \"All edits that are one edit away from `word`.\"\n",
    "#     letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "#     deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "#     return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# def edits2(word): \n",
    "#     \"All edits that are two edits away from `word`.\"\n",
    "#     return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten a list of two tuples\n",
    "def lst_flatten(lst):\n",
    "    ret = []\n",
    "    for a,b in lst:\n",
    "        ret.append(a)\n",
    "        ret.append(b)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> importing  dataset #1\n",
      "The Project Gutenberg EBook of The Adventures of Sherlock Holmes\n",
      "by Sir Arthur Conan Doyle\n",
      "(#15 in our series by Sir Arthur Cona\n",
      "\n",
      ">>> importing  dataset #2\n",
      "The frequency distribution for attribute 'lemma' in corpus 'internet-en'\n",
      "For more information visit http://corpus.leeds.ac.uk/li\n",
      "\n",
      ">>> importing  dataset #3\n",
      "you 6281002\n",
      "i 5685306\n",
      "the 4768490\n",
      "to 3453407\n",
      "a 3048287\n",
      "it 2879962\n",
      "and 2127187\n",
      "that 2030642\n",
      "of 1847884\n",
      "in 1554103\n",
      "what 1497273\n",
      "is\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yuge_data = \"\"\n",
    "\n",
    "cnt = 1\n",
    "dataset_lst = [\"yuge_data.txt\", \"internet-en.num.txt\", \"en.txt\"]\n",
    "for d in dataset_lst:\n",
    "    data_import = open(d).read()\n",
    "    yuge_data += data_import\n",
    "    print(\">>> importing  dataset #\" + str(cnt))\n",
    "    print(data_import[:128])\n",
    "    print()\n",
    "\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_words(src):\n",
    "    # allow upper case words\n",
    "    return re.findall(r'\\b\\w+\\b', src)\n",
    "#     return re.findall(r'\\b\\w+\\b', src.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 210511),\n",
       " ('the', 72296),\n",
       " ('2', 64161),\n",
       " ('of', 39717),\n",
       " ('and', 36894),\n",
       " ('3', 31024),\n",
       " ('to', 28269)]"
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a regex test\n",
    "# tst_str = \"The Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in our series by Sir Arthur Conan Doyle)\\n\\nCopyright laws are changing all over the world. Be sure to check the\\ncopyright laws for your country before downloadin\"\n",
    "# re.findall(r'\\b\\w+\\b',tst_str)\n",
    "\n",
    "extract_words(yuge_data)\n",
    "WORD_IDX = Counter(extract_words(yuge_data))\n",
    "\n",
    "# retrieve the 7 most common words\n",
    "WORD_IDX.most_common(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how likely is a given word?\n",
    "\n",
    "# get the sum of all words\n",
    "ALL_WORD_CNT = sum(WORD_IDX.values())\n",
    "\n",
    "# get the number of occurrences \n",
    "WORD_IDX.values()\n",
    "\n",
    "# probability function\n",
    "def ProbabilityForWord(word):\n",
    "    return WORD_IDX[word]/ALL_WORD_CNT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# TODO: define a recursive candidate function\\n# (this kinda like DFS)\\ndef candidates_n(word, n):\\n    if (n == 1):\\n        candidates_1(word)\\n    else:\\n        for a in candidates_1(word):\\n            for b in candidates\\n\\n# tests\\n# candidates_1(\"pineapple\")\\n# candidates_n(\"pineapple\", 1)\\n# candidates_n(\"q\", 1)\\n'"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building our candidate model\n",
    "# (this boils down to generating possible words \n",
    "#  based on simple string manipulation)\n",
    "\n",
    "\n",
    "# [print(x) for x in s]\n",
    "# print()\n",
    "# [print(x) for x in d]\n",
    "# print()\n",
    "# [print(x) for x in t]\n",
    "# print()\n",
    "# [print(x) for x in r]\n",
    "# print()\n",
    "# [print(x) for x in i]\n",
    "# print()\n",
    "\n",
    "def candidates_1(word):\n",
    "    # \"\".join([chr(c) for c in range(65, 91)])\n",
    "    alphab = 'abcdefghijklmnopqrstuvwxyz'+'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "    # edits formed by inserting a space\n",
    "    s = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "\n",
    "    # edits formed by deleting a character\n",
    "    d = [L + R[1:] for L, R in s if R]\n",
    "\n",
    "    # edits formed by swapping the i'th and (i+1)'th characters\n",
    "    # where i < len(word) - 1\n",
    "    t = [L + R[1] + R[0] + R[2:] for L, R in s if len(R)>1] \n",
    "    # TODO: consider adding transposes of a longer length \n",
    "    # (i.e., three or four letter transposes)\n",
    "\n",
    "    # edits formed by substituting a random character\n",
    "    # (similar to: \"edits formed by inserting a space\" as shown above)\n",
    "    r = []\n",
    "    for L, R in s:\n",
    "        if R:\n",
    "            for c in alphab:\n",
    "                r.append( L + c + R[1:] )\n",
    "\n",
    "    # edits formed by inserting a random char\n",
    "    i = [L + c + R for L, R in s for c in alphab]\n",
    "\n",
    "    # dont exclude split words\n",
    "    # consider them as candidates\n",
    "    s = lst_flatten(s)\n",
    "\n",
    "    # return all: splits, deletes, edits, replacements, and insertions\n",
    "    return set(s + d + t + r + i)\n",
    "\n",
    "'''\n",
    "# TODO: define a recursive candidate function\n",
    "# (this kinda like DFS)\n",
    "def candidates_n(word, n):\n",
    "    if (n == 1):\n",
    "        candidates_1(word)\n",
    "    else:\n",
    "        for a in candidates_1(word):\n",
    "            for b in candidates\n",
    "\n",
    "# tests\n",
    "# candidates_1(\"pineapple\")\n",
    "# candidates_n(\"pineapple\", 1)\n",
    "# candidates_n(\"q\", 1)\n",
    "'''\n",
    "\n",
    "# TODO: fix this (not working for some reason)\n",
    "# def candidates_2(word):\n",
    "#     \"All edits that are two edits away from `word`.\"\n",
    "#     return (e2 for e1 in candidates_1(word) for e2 in candidates_1(e1))\n",
    "\n",
    "# candidates_2(\"pineapple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can a given word be found in the \"dictionary\"?\n",
    "def only_words_in_dict(words):\n",
    "    assert( type(words) == set )\n",
    "    return set(w for w in words if WORD_IDX[w] > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob(the) 0.03427271688648087\n",
      "prob(pineapple) 1.422183117453837e-06\n",
      "pineapple 3\n",
      "all words 2109433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('apple', 13),\n",
       " ('neapple', 1),\n",
       " ('p', 43),\n",
       " ('pineaple', 1),\n",
       " ('le', 45),\n",
       " ('pineapples', 3),\n",
       " ('pineappple', 1),\n",
       " ('ple', 1),\n",
       " ('pi', 2),\n",
       " ('pin', 20),\n",
       " ('pineapple', 3),\n",
       " ('e', 30),\n",
       " ('pple', 1),\n",
       " ('pine', 11)]"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === unit/regression tests\n",
    "\n",
    "print(\"prob(the)\", ProbabilityForWord('the'))\n",
    "print(\"prob(pineapple)\", ProbabilityForWord(\"pineapple\"))\n",
    "print(\"pineapple\", WORD_IDX[\"pineapple\"])\n",
    "print(\"all words\", ALL_WORD_CNT)\n",
    "\n",
    "# A = 65\n",
    "# Z = 90\n",
    "for upper_case_letter in range(65, 91):\n",
    "    assert( ProbabilityForWord(upper_case_letter) < 1 )\n",
    "    assert( ProbabilityForWord(upper_case_letter) >= 0 )\n",
    "    assert( WORD_IDX[upper_case_letter] < ALL_WORD_CNT )\n",
    "\n",
    "# a = 97\n",
    "# z = 122\n",
    "for lower_case_letter in range(97, 123):\n",
    "    assert( ProbabilityForWord(lower_case_letter) < 1 )\n",
    "    assert( ProbabilityForWord(lower_case_letter) >= 0 )\n",
    "    assert( WORD_IDX[lower_case_letter] < ALL_WORD_CNT )\n",
    "\n",
    "common_words = [\"the\", \"i\", \"I\", \"am\"]\n",
    "for c in common_words:\n",
    "    assert( ProbabilityForWord(c) < 1)\n",
    "\n",
    "# generate all possible edits for a word\n",
    "tst_word = \"pineapple\"\n",
    "[(a, WORD_IDX[a]) for a in only_words_in_dict(candidates_1(tst_word))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

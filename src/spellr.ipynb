{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######                       #######\n",
    "####### Presenting: Spellr.AI #######\n",
    "#######                       #######\n",
    "\n",
    "####### section 00\n",
    "####### loading libraries\n",
    "\n",
    "\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> importing  dataset #1\n",
      "The Project Gutenberg EBook of The Adventures of Sherlock Holmes\n",
      "\n",
      ">>> importing  dataset #2\n",
      "The frequency distribution for attribute 'lemma' in corpus 'inte\n",
      "\n",
      ">>> importing  dataset #3\n",
      "you 6281002\n",
      "i 5685306\n",
      "the 4768490\n",
      "to 3453407\n",
      "a 3048287\n",
      "it 287996\n",
      "\n",
      ">>> importing  dataset #4\n",
      "2\n",
      "1080\n",
      "&c\n",
      "10-point\n",
      "10th\n",
      "11-point\n",
      "12-point\n",
      "16-point\n",
      "18-point\n",
      "1st\n",
      "\n",
      "\n",
      ">>> importing  dataset #5\n",
      "a\n",
      "aa\n",
      "aaa\n",
      "aah\n",
      "aahed\n",
      "aahing\n",
      "aahs\n",
      "aal\n",
      "aalii\n",
      "aaliis\n",
      "aals\n",
      "aam\n",
      "aani\n",
      "aa\n",
      "\n",
      ">>> importing  dataset #6\n",
      "a\n",
      "aa\n",
      "aaa\n",
      "aachen\n",
      "aardvark\n",
      "aardvarks\n",
      "aardwolf\n",
      "aardwolves\n",
      "aarhus\n",
      "aa\n",
      "\n",
      ">>> importing  dataset #7\n",
      "a\n",
      "aa\n",
      "aaa\n",
      "aachen\n",
      "aardvark\n",
      "aardvarks\n",
      "aaron\n",
      "aback\n",
      "abacus\n",
      "abacuses\n",
      "a\n",
      "\n",
      ">>> importing  dataset #8\n",
      "a\n",
      "aa\n",
      "aaa\n",
      "aachen\n",
      "aardvark\n",
      "aardvarks\n",
      "aaron\n",
      "aback\n",
      "abacus\n",
      "abacuses\n",
      "a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####### section 01\n",
    "####### loading databases\n",
    "\n",
    "\n",
    "dataset_lst = []\n",
    "dataset_lst.append(\"yuge_data.txt\")\n",
    "dataset_lst.append(\"internet-en.num.txt\")\n",
    "dataset_lst.append(\"en.txt\")\n",
    "dataset_lst.append(\"words.txt\")\n",
    "dataset_lst.append(\"words_alpha.txt\")\n",
    "dataset_lst.append(\"english3.txt\")\n",
    "dataset_lst.append(\"english2.txt\")\n",
    "dataset_lst.append(\"usa.txt\")\n",
    "\n",
    "# these dont work (because they contain non utf-8 chars)\n",
    "# dataset_lst.append(\"ukenglish.txt\")\n",
    "# dataset_lst.append(\"engmix.txt\")\n",
    "# dataset_lst.append(\"usa2.txt\")\n",
    "\n",
    "yuge_data = \"\"\n",
    "cnt = 1\n",
    "for d in dataset_lst:\n",
    "    data_import = open(\"../datasets/\"+d).read()\n",
    "    yuge_data += data_import\n",
    "    print(\">>> importing  dataset #\" + str(cnt))\n",
    "    print(data_import[:64])\n",
    "    print()\n",
    "\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[i] the 1st 10 words in all the databases\n",
      "['The',\n",
      " 'Project',\n",
      " 'Gutenberg',\n",
      " 'EBook',\n",
      " 'of',\n",
      " 'The',\n",
      " 'Adventures',\n",
      " 'of',\n",
      " 'Sherlock',\n",
      " 'Holmes']\n",
      "\n",
      "[i] retrieve the most common words\n",
      "[('the', 72390),\n",
      " ('of', 39844),\n",
      " ('and', 37067),\n",
      " ('to', 28370),\n",
      " ('in', 20227),\n",
      " ('that', 11994),\n",
      " ('was', 11372),\n",
      " ('he', 10062),\n",
      " ('is', 9648),\n",
      " ('his', 9628),\n",
      " ('with', 9501),\n",
      " ('it', 8572),\n",
      " ('as', 7487),\n",
      " ('had', 7337),\n",
      " ('The', 7245),\n",
      " ('for', 6671),\n",
      " ('by', 6651),\n",
      " ('not', 6485),\n",
      " ('at', 6360)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####### section 02\n",
    "####### processing databases\n",
    "\n",
    "\n",
    "def extract_words(src):\n",
    "    res = src\n",
    "\n",
    "    # distinguish between upper/lower case words\n",
    "    res = re.findall(r'\\b\\w+\\b', src)\n",
    "\n",
    "    # filter out numbers\n",
    "    res = list(itertools.filterfalse(lambda x: x.isnumeric(), res))\n",
    "\n",
    "    # filter out words of length 1\n",
    "    res = list(itertools.filterfalse(lambda x: len(x) == 1, res))\n",
    "\n",
    "    return res\n",
    "\n",
    "print(\"\\n[i] the 1st 10 words in all the databases\")\n",
    "pprint( extract_words(yuge_data)[:10] )\n",
    "WORD_IDX = Counter(extract_words(yuge_data))\n",
    "\n",
    "print(\"\\n[i] retrieve the most common words\")\n",
    "pprint( WORD_IDX.most_common(19) )\n",
    "\n",
    "# get the sum of all words\n",
    "ALL_WORD_CNT = sum(WORD_IDX.values())\n",
    "\n",
    "# get the number of occurrences \n",
    "WORD_IDX.values()\n",
    "\n",
    "# probability function\n",
    "# used to help answer the question: how likely is a given word?\n",
    "def ProbabilityForWord(word):\n",
    "    return WORD_IDX[word]/ALL_WORD_CNT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "####### section 03\n",
    "####### building a candidate model\n",
    "        # (this boils down to generating possible \n",
    "        #  words with simple string manipulation)\n",
    "\n",
    "\n",
    "# === helper functions\n",
    "# flatten a list of two tuples\n",
    "def lst_flatten(lst):\n",
    "    ret = []\n",
    "    for a,b in lst:\n",
    "        ret.append(a)\n",
    "        ret.append(b)\n",
    "    return ret\n",
    "\n",
    "# can a given word be found in the \"dictionary\"?\n",
    "def only_words_in_dict(words):\n",
    "    assert( type(words) == set )\n",
    "    return set(w for w in words if WORD_IDX[w] > 0)\n",
    "\n",
    "\n",
    "\n",
    "def candidates_1(word):\n",
    "    # \"\".join([chr(c) for c in range(65, 91)])\n",
    "    alphab = 'abcdefghijklmnopqrstuvwxyz'+'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "    # edits formed by inserting a space\n",
    "    s = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "\n",
    "    # edits formed by deleting a character\n",
    "    d = [L + R[1:] for L, R in s if R]\n",
    "\n",
    "    # edits formed by swapping the i'th and (i+1)'th characters\n",
    "    # where i < len(word) - 1\n",
    "    t = [L + R[1] + R[0] + R[2:] for L, R in s if len(R)>1] \n",
    "    # ?? consider adding transposes of a longer length \n",
    "    # (i.e., three or four letter transposes)\n",
    "\n",
    "    # edits formed by substituting a random character\n",
    "    # (similar to: \"edits formed by inserting a space\" as shown above)\n",
    "    r = []\n",
    "    for L, R in s:\n",
    "        if R:\n",
    "            for c in alphab:\n",
    "                r.append( L + c + R[1:] )\n",
    "\n",
    "    # edits formed by inserting a random char\n",
    "    i = [L + c + R for L, R in s for c in alphab]\n",
    "\n",
    "    # dont exclude split words\n",
    "    # consider them as candidates\n",
    "    s = lst_flatten(s)\n",
    "\n",
    "    # return all: splits, deletes, edits, replacements, and insertions\n",
    "    return set(s + d + t + r + i)\n",
    "\n",
    "# This code kinda works, but note that when n >= 3, the function \"blows up\".\n",
    "# Finding all edits of distance >= 3 is computationally hard.\n",
    "def candidates_n(word, n):\n",
    "    if (n == 1):\n",
    "        return candidates_1(word)\n",
    "    else: \n",
    "        res = set()\n",
    "        for a in candidates_n(word, n-1):\n",
    "            \n",
    "            # Note: the for loop below is not part of the\n",
    "            # recursion. it's used for flattening the set.\n",
    "            for z in candidates_1(a):\n",
    "                res.add(z)\n",
    "        return res\n",
    "\n",
    "def candidates(word):\n",
    "    res = set()\n",
    "    for e1 in only_words_in_dict(candidates_n(word, 1)):\n",
    "        res.add(e1)\n",
    "    for e2 in only_words_in_dict(candidates_n(word, 2)):\n",
    "        res.add(e2)\n",
    "\n",
    "    # res.add(word)\n",
    "\n",
    "    # sort according to the following:\n",
    "        # favour longer words over shorter ones\n",
    "        # favour more frequent words over less frequent words\n",
    "    res = sorted(res, key=lambda elmt:(len(elmt), WORD_IDX[elmt]), reverse=True)\n",
    "\n",
    "    return res\n",
    "\n",
    "def best_guess(word):\n",
    "    return candidates(word)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] ProbabilityForWord(\"the\"): 0.026366561125148104\n",
      "[i] ProbabilityForWord(\"pineapple\"): 3.2780639608555458e-06\n",
      "[i] pineapple occurs 9 times in all datasets\n",
      "[i] all words: 2745523\n",
      "\n",
      "[word: toothhick] best guess: toothpicks\n",
      "probability: 2.185375973903697e-06\n",
      "[word: toothhick] 5 other possible guesses toothhick\n",
      "\t(toothstick, 2)\n",
      "\t(toothpick, 7)\n",
      "\t(tothick, 1)\n",
      "\t(toothy, 7)\n",
      "\t(tooths, 4)\n",
      "\n",
      "[word: princeron] best guess: princetown\n",
      "probability: 1.0926879869518486e-06\n",
      "[word: princeron] 5 other possible guesses princeron\n",
      "\t(princetons, 1)\n",
      "\t(princeton, 6)\n",
      "\t(Princeton, 5)\n",
      "\t(princedom, 4)\n",
      "\t(princekin, 3)\n",
      "\n",
      "[word: jupytir] best guess: jupiter\n",
      "probability: 2.5496053028876466e-06\n",
      "[word: jupytir] 5 other possible guesses jupytir\n",
      "\t(jupitar, 1)\n",
      "\t(jupatis, 1)\n",
      "\t(juplter, 1)\n",
      "\t(jupati, 3)\n",
      "\t(upstir, 2)\n",
      "\n",
      "[word: mashuo] best guess: smashup\n",
      "probability: 1.0926879869518486e-06\n",
      "[word: mashuo] 5 other possible guesses mashuo\n",
      "\t(mashlum, 2)\n",
      "\t(mashful, 1)\n",
      "\t(machuto, 1)\n",
      "\t(mashkov, 1)\n",
      "\t(masculo, 1)\n",
      "\n",
      "[word: pineappee] best guess: pineapples\n",
      "probability: 2.913834631871596e-06\n",
      "[word: pineappee] 5 other possible guesses pineappee\n",
      "\t(pineappple, 1)\n",
      "\t(pineappies, 1)\n",
      "\t(pineapple, 9)\n",
      "\t(pineaple, 1)\n",
      "\t(pinesap, 2)\n",
      "\n",
      "[word: that] best guess: throat\n",
      "probability: 2.950257564769991e-05\n",
      "[word: that] 5 other possible guesses that\n",
      "\t(threat, 18)\n",
      "\t(thwart, 10)\n",
      "\t(thatch, 9)\n",
      "\t(thanet, 3)\n",
      "\t(thatll, 2)\n",
      "\n",
      "[word: peele] best guess: peelers\n",
      "probability: 2.185375973903697e-06\n",
      "[word: peele] 5 other possible guesses peele\n",
      "\t(peebles, 3)\n",
      "\t(speeled, 3)\n",
      "\t(peelite, 2)\n",
      "\t(speedle, 1)\n",
      "\t(peeleep, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0926879869518486e-06"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### section 04\n",
    "####### unit testing\n",
    "\n",
    "\n",
    "print(\"[i] ProbabilityForWord(\\\"the\\\"):\", ProbabilityForWord('the'))\n",
    "print(\"[i] ProbabilityForWord(\\\"pineapple\\\"):\", ProbabilityForWord(\"pineapple\"))\n",
    "print(\"[i] pineapple occurs\", WORD_IDX[\"pineapple\"], \"times in all datasets\")\n",
    "print(\"[i] all words:\", ALL_WORD_CNT)\n",
    "\n",
    "# assertions\n",
    "assert(candidates_1(\"pineapple\") == candidates_n(\"pineapple\", 1))\n",
    "\n",
    "for upper_case_letter in range(65, 91): # A = 65, # Z = 90\n",
    "    assert( ProbabilityForWord(upper_case_letter) < 1 )\n",
    "    assert( ProbabilityForWord(upper_case_letter) >= 0 )\n",
    "    assert( WORD_IDX[upper_case_letter] < ALL_WORD_CNT )\n",
    "\n",
    "for lower_case_letter in range(97, 123): # a = 97, # z = 122\n",
    "    assert( ProbabilityForWord(lower_case_letter) < 1 )\n",
    "    assert( ProbabilityForWord(lower_case_letter) >= 0 )\n",
    "    assert( WORD_IDX[lower_case_letter] < ALL_WORD_CNT )\n",
    "\n",
    "# ensure that the most common words \n",
    "# have reasonable probabilities\n",
    "common_words = [elmt[0] for elmt in WORD_IDX.most_common(100)]\n",
    "for c in common_words:\n",
    "    assert( ProbabilityForWord(c) < 1)\n",
    "\n",
    "# for each of these words, generate the best seven guesses\n",
    "\n",
    "guess = []\n",
    "guess.append(\"toothhick\")\n",
    "guess.append(\"princeron\")\n",
    "guess.append(\"jupytir\")\n",
    "guess.append(\"mashuo\")\n",
    "guess.append(\"pineappee\")\n",
    "guess.append(\"that\")\n",
    "guess.append(\"peele\")\n",
    "\n",
    "for g in guess:\n",
    "    print( \"\\n[word: \" + g + \"] best guess: \" + best_guess(g) )\n",
    "    print( \"probability: \" \n",
    "          + str( ProbabilityForWord(best_guess(g)) ) \n",
    "          + \"\" )\n",
    "\n",
    "    print( \"[word: \" + g + \"] 5 other possible guesses \" + g )\n",
    "    for x in candidates(g)[1:6]:\n",
    "        print( \"\\t(\" + x + \", \" + str(WORD_IDX[x]) + \")\" )\n",
    "\n",
    "ProbabilityForWord(\"princetown\")\n",
    "\n",
    "# credits to: https://norvig.com/spell-correct.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
